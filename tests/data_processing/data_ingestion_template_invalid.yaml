# copy-paste this template into a data_ingestion_template.yaml before using
# as a best practice, config.yaml must not be committed to github
# as it may contain sensitive information about the data.


# the name of requestor
requestor:

# the department to which the requestor belongs
requestor_department:

# email address of requestor
requestor_email:

# project name decided by data coordination
project:

# source name of input data file
source:

# data modality
modality:

# data type within the modality
data_type: CAT

# description of the template defined by the requestor
comments:

# the data on which the request was made
date: 2020-10-29

# name to be given to the dataset
dataset_name: OV_16-158_CT_20201028

# Type of ETL
etl_type: proxy

# input source file. examples "csv", "dcm"
file_type: dcm

# ip or hostname of machine where source data file(s) reside, if applicable
host:

# file path to the source data file(s). if host is specified, the source data location is determined
# as host:source_path
source_path: /data

# file path to location where the data should be transferred on the destination machine.
destination_path: /data

# a comma separated list of files types/extensions to exclude. for example, leave empty to include all files.
exclude: mah,mhd,raw

# total number of input data files to process. this can be obtained by running the following command on the source directory
# 'find <source_dir> -type f -name "*.dcm" -o -name "*.mha" | wc -l'
file_count: 1000000

# total number of bytes to be transfered. this can be obtained by running the following command on the source directory
# 'find <source_dir> -type f -name "*.dcm" -o -name "*.mha" | xargs du -ac'
data_size: 291337979

bwlimit: 5T